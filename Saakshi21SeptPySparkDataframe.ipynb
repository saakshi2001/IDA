{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0969fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796c5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f5363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3214a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/21 08:36:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/21 08:36:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#create a SparkSession\n",
    "spark=SparkSession.builder.appName(\"RDDExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218f01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "| _1| _2| _3|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(1,2,3)])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d20da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  4|5.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55861c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema='a long, b double, c string, d date, e timestamp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80782967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "]\n",
    "df1=spark.createDataFrame(data,schema)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "917ff85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=[(1,'a','z',777700,'India'),(2,'b','y',9890,'India')]\n",
    "schema2=\"id int, name string, last_name string, mo int, country string\"\n",
    "df2=spark.createDataFrame(data2,schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe4989f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---------+------+-------+\n",
      "| id|name|last_name|    mo|country|\n",
      "+---+----+---------+------+-------+\n",
      "|  1|   a|        z|777700|  India|\n",
      "|  2|   b|        y|  9890|  India|\n",
      "+---+----+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad10daab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('name', 'string'),\n",
       " ('last_name', 'string'),\n",
       " ('mo', 'int'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99aac3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---------+-------------+-------+\n",
      "| id|name|last_name|mobile_number|country|\n",
      "+---+----+---------+-------------+-------+\n",
      "|  1|   a|        z|       777700|  India|\n",
      "|  2|   b|        y|         9890|  India|\n",
      "+---+----+---------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shem_list=['id','name','last_name','mobile_number','country']\n",
    "df3=spark.createDataFrame(data2,shem_list)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3275d34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('last_name', 'string'),\n",
       " ('mobile_number', 'bigint'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09fadf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- mobile_number: long (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "966186d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+\n",
      "|amt_paid|fname| id|\n",
      "+--------+-----+---+\n",
      "|    1000|    a|  1|\n",
      "|    1200|    b|  2|\n",
      "+--------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users=[{'id':1,'fname':'a','amt_paid':1000},{'id':2,'fname':'b','amt_paid':1200}] #json file format\n",
    "df4=spark.createDataFrame(users)\n",
    "df4.show() #table has columns arranged in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86abf108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9233b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "|       _c0|   _c1|       _c2|            _c3|   _c4|    _c5|              _c6|                 _c7|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "|First Name|Gender|Start Date|Last Login Time|Salary|Bonus %|Senior Management|                Team|\n",
      "|   Douglas|  Male|  8/6/1993|       12:42 PM| 97308|  6.945|             true|           Marketing|\n",
      "|    Thomas|  Male| 3/31/1996|        6:53 AM| 61933|   4.17|             true|                null|\n",
      "|     Maria|Female| 4/23/1993|       11:17 AM|130590| 11.858|            false|             Finance|\n",
      "|     Jerry|  Male|  3/4/2005|        1:00 PM|138705|   9.34|             true|             Finance|\n",
      "|     Larry|  Male| 1/24/1998|        4:47 PM|101004|  1.389|             true|     Client Services|\n",
      "|    Dennis|  Male| 4/18/1987|        1:35 AM|115163| 10.125|            false|               Legal|\n",
      "|      Ruby|Female| 8/17/1987|        4:20 PM| 65476| 10.012|             true|             Product|\n",
      "|      null|Female| 7/20/2015|       10:43 AM| 45906| 11.598|             null|             Finance|\n",
      "|    Angela|Female|11/22/2005|        6:29 AM| 95570| 18.523|             true|         Engineering|\n",
      "|   Frances|Female|  8/8/2002|        6:51 AM|139852|  7.524|             true|Business Development|\n",
      "|    Louise|Female| 8/12/1980|        9:01 AM| 63241| 15.132|             true|                null|\n",
      "|     Julie|Female|10/26/1997|        3:19 PM|102508| 12.637|             true|               Legal|\n",
      "|   Brandon|  Male| 12/1/1980|        1:08 AM|112807| 17.492|             true|     Human Resources|\n",
      "|      Gary|  Male| 1/27/2008|       11:40 PM|109831|  5.831|            false|               Sales|\n",
      "|  Kimberly|Female| 1/14/1999|        7:13 AM| 41426| 14.543|             true|             Finance|\n",
      "|   Lillian|Female|  6/5/2016|        6:09 AM| 59414|  1.256|            false|             Product|\n",
      "|    Jeremy|  Male| 9/21/2010|        5:56 AM| 90370|  7.369|            false|     Human Resources|\n",
      "|     Shawn|  Male| 12/7/1986|        7:45 PM|111737|  6.414|            false|             Product|\n",
      "|     Diana|Female|10/23/1981|       10:27 AM|132940| 19.082|            false|     Client Services|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90126024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "|First Name|Gender|Start Date|Last Login Time|Salary|Bonus %|Senior Management|                Team|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "|   Douglas|  Male|  8/6/1993|       12:42 PM| 97308|  6.945|             true|           Marketing|\n",
      "|    Thomas|  Male| 3/31/1996|        6:53 AM| 61933|   4.17|             true|                null|\n",
      "|     Maria|Female| 4/23/1993|       11:17 AM|130590| 11.858|            false|             Finance|\n",
      "|     Jerry|  Male|  3/4/2005|        1:00 PM|138705|   9.34|             true|             Finance|\n",
      "|     Larry|  Male| 1/24/1998|        4:47 PM|101004|  1.389|             true|     Client Services|\n",
      "|    Dennis|  Male| 4/18/1987|        1:35 AM|115163| 10.125|            false|               Legal|\n",
      "|      Ruby|Female| 8/17/1987|        4:20 PM| 65476| 10.012|             true|             Product|\n",
      "|      null|Female| 7/20/2015|       10:43 AM| 45906| 11.598|             null|             Finance|\n",
      "|    Angela|Female|11/22/2005|        6:29 AM| 95570| 18.523|             true|         Engineering|\n",
      "|   Frances|Female|  8/8/2002|        6:51 AM|139852|  7.524|             true|Business Development|\n",
      "|    Louise|Female| 8/12/1980|        9:01 AM| 63241| 15.132|             true|                null|\n",
      "|     Julie|Female|10/26/1997|        3:19 PM|102508| 12.637|             true|               Legal|\n",
      "|   Brandon|  Male| 12/1/1980|        1:08 AM|112807| 17.492|             true|     Human Resources|\n",
      "|      Gary|  Male| 1/27/2008|       11:40 PM|109831|  5.831|            false|               Sales|\n",
      "|  Kimberly|Female| 1/14/1999|        7:13 AM| 41426| 14.543|             true|             Finance|\n",
      "|   Lillian|Female|  6/5/2016|        6:09 AM| 59414|  1.256|            false|             Product|\n",
      "|    Jeremy|  Male| 9/21/2010|        5:56 AM| 90370|  7.369|            false|     Human Resources|\n",
      "|     Shawn|  Male| 12/7/1986|        7:45 PM|111737|  6.414|            false|             Product|\n",
      "|     Diana|Female|10/23/1981|       10:27 AM|132940| 19.082|            false|     Client Services|\n",
      "|     Donna|Female| 7/22/2010|        3:48 AM| 81014|  1.894|            false|             Product|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.option(\"header\",True).csv('emp.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ee93ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Start Date: string (nullable = true)\n",
      " |-- Last Login Time: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      " |-- Bonus %: string (nullable = true)\n",
      " |-- Senior Management: string (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()  #all datatypes are stings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20f44a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Start Date: string (nullable = true)\n",
      " |-- Last Login Time: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Bonus %: double (nullable = true)\n",
      " |-- Senior Management: boolean (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.option(\"header\",True).option(\"inferschema\",True).csv('emp.csv')\n",
    "df.printSchema() #all datatypes are not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2e3b3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|First Name|Gender|\n",
      "+----------+------+\n",
      "|   Douglas|  Male|\n",
      "|    Thomas|  Male|\n",
      "|     Maria|Female|\n",
      "|     Jerry|  Male|\n",
      "|     Larry|  Male|\n",
      "|    Dennis|  Male|\n",
      "|      Ruby|Female|\n",
      "|      null|Female|\n",
      "|    Angela|Female|\n",
      "|   Frances|Female|\n",
      "|    Louise|Female|\n",
      "|     Julie|Female|\n",
      "|   Brandon|  Male|\n",
      "|      Gary|  Male|\n",
      "|  Kimberly|Female|\n",
      "|   Lillian|Female|\n",
      "|    Jeremy|  Male|\n",
      "|     Shawn|  Male|\n",
      "|     Diana|Female|\n",
      "|     Donna|Female|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"First Name\",\"Gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "902b1833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Forename|\n",
      "+--------+\n",
      "| Douglas|\n",
      "|  Thomas|\n",
      "|   Maria|\n",
      "|   Jerry|\n",
      "|   Larry|\n",
      "|  Dennis|\n",
      "|    Ruby|\n",
      "|    null|\n",
      "|  Angela|\n",
      "| Frances|\n",
      "|  Louise|\n",
      "|   Julie|\n",
      "| Brandon|\n",
      "|    Gary|\n",
      "|Kimberly|\n",
      "| Lillian|\n",
      "|  Jeremy|\n",
      "|   Shawn|\n",
      "|   Diana|\n",
      "|   Donna|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"First Name\").alias(\"Forename\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8fbef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+\n",
      "|First Name|Gender|                Team|\n",
      "+----------+------+--------------------+\n",
      "|   Douglas|  Male|           Marketing|\n",
      "|    Thomas|  Male|                null|\n",
      "|     Maria|Female|             Finance|\n",
      "|     Jerry|  Male|             Finance|\n",
      "|     Larry|  Male|     Client Services|\n",
      "|    Dennis|  Male|               Legal|\n",
      "|      Ruby|Female|             Product|\n",
      "|      null|Female|             Finance|\n",
      "|    Angela|Female|         Engineering|\n",
      "|   Frances|Female|Business Development|\n",
      "|    Louise|Female|                null|\n",
      "|     Julie|Female|               Legal|\n",
      "|   Brandon|  Male|     Human Resources|\n",
      "|      Gary|  Male|               Sales|\n",
      "|  Kimberly|Female|             Finance|\n",
      "|   Lillian|Female|             Product|\n",
      "|    Jeremy|  Male|     Human Resources|\n",
      "|     Shawn|  Male|             Product|\n",
      "|     Diana|Female|     Client Services|\n",
      "|     Donna|Female|             Product|\n",
      "+----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"First Name\",col(\"Gender\"),df[\"Team\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4151ae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "|First Name|   Sex|Start Date|Last Login Time|Salary|Bonus %|Senior Management|                Team|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "|   Douglas|  Male|  8/6/1993|       12:42 PM| 97308|  6.945|             true|           Marketing|\n",
      "|    Thomas|  Male| 3/31/1996|        6:53 AM| 61933|   4.17|             true|                null|\n",
      "|     Maria|Female| 4/23/1993|       11:17 AM|130590| 11.858|            false|             Finance|\n",
      "|     Jerry|  Male|  3/4/2005|        1:00 PM|138705|   9.34|             true|             Finance|\n",
      "|     Larry|  Male| 1/24/1998|        4:47 PM|101004|  1.389|             true|     Client Services|\n",
      "|    Dennis|  Male| 4/18/1987|        1:35 AM|115163| 10.125|            false|               Legal|\n",
      "|      Ruby|Female| 8/17/1987|        4:20 PM| 65476| 10.012|             true|             Product|\n",
      "|      null|Female| 7/20/2015|       10:43 AM| 45906| 11.598|             null|             Finance|\n",
      "|    Angela|Female|11/22/2005|        6:29 AM| 95570| 18.523|             true|         Engineering|\n",
      "|   Frances|Female|  8/8/2002|        6:51 AM|139852|  7.524|             true|Business Development|\n",
      "|    Louise|Female| 8/12/1980|        9:01 AM| 63241| 15.132|             true|                null|\n",
      "|     Julie|Female|10/26/1997|        3:19 PM|102508| 12.637|             true|               Legal|\n",
      "|   Brandon|  Male| 12/1/1980|        1:08 AM|112807| 17.492|             true|     Human Resources|\n",
      "|      Gary|  Male| 1/27/2008|       11:40 PM|109831|  5.831|            false|               Sales|\n",
      "|  Kimberly|Female| 1/14/1999|        7:13 AM| 41426| 14.543|             true|             Finance|\n",
      "|   Lillian|Female|  6/5/2016|        6:09 AM| 59414|  1.256|            false|             Product|\n",
      "|    Jeremy|  Male| 9/21/2010|        5:56 AM| 90370|  7.369|            false|     Human Resources|\n",
      "|     Shawn|  Male| 12/7/1986|        7:45 PM|111737|  6.414|            false|             Product|\n",
      "|     Diana|Female|10/23/1981|       10:27 AM|132940| 19.082|            false|     Client Services|\n",
      "|     Donna|Female| 7/22/2010|        3:48 AM| 81014|  1.894|            false|             Product|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"Gender\",\"Sex\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edcdd4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|concat(Start Date, Last Login Time)|\n",
      "+-----------------------------------+\n",
      "|                   8/6/199312:42 PM|\n",
      "|                   3/31/19966:53 AM|\n",
      "|                  4/23/199311:17 AM|\n",
      "|                    3/4/20051:00 PM|\n",
      "|                   1/24/19984:47 PM|\n",
      "|                   4/18/19871:35 AM|\n",
      "|                   8/17/19874:20 PM|\n",
      "|                  7/20/201510:43 AM|\n",
      "|                  11/22/20056:29 AM|\n",
      "|                    8/8/20026:51 AM|\n",
      "|                   8/12/19809:01 AM|\n",
      "|                  10/26/19973:19 PM|\n",
      "|                   12/1/19801:08 AM|\n",
      "|                  1/27/200811:40 PM|\n",
      "|                   1/14/19997:13 AM|\n",
      "|                    6/5/20166:09 AM|\n",
      "|                   9/21/20105:56 AM|\n",
      "|                   12/7/19867:45 PM|\n",
      "|                 10/23/198110:27 AM|\n",
      "|                   7/22/20103:48 AM|\n",
      "+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "#df.concat(\"Start Date\",\"Last Login Time\") will not work as concat is not a dataframe function\n",
    "df.select(concat(\"Start Date\",\"Last Login Time\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4edb3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+--------------------+\n",
      "|First Name|Gender|Start Date|Last Login Time|Salary|Bonus %|Senior Management|                Team|         Date & Time|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+--------------------+\n",
      "|   Douglas|  Male|  8/6/1993|       12:42 PM| 97308|  6.945|             true|           Marketing|8/6/1993  &  12:4...|\n",
      "|    Thomas|  Male| 3/31/1996|        6:53 AM| 61933|   4.17|             true|                null|3/31/1996  &  6:5...|\n",
      "|     Maria|Female| 4/23/1993|       11:17 AM|130590| 11.858|            false|             Finance|4/23/1993  &  11:...|\n",
      "|     Jerry|  Male|  3/4/2005|        1:00 PM|138705|   9.34|             true|             Finance|3/4/2005  &  1:00 PM|\n",
      "|     Larry|  Male| 1/24/1998|        4:47 PM|101004|  1.389|             true|     Client Services|1/24/1998  &  4:4...|\n",
      "|    Dennis|  Male| 4/18/1987|        1:35 AM|115163| 10.125|            false|               Legal|4/18/1987  &  1:3...|\n",
      "|      Ruby|Female| 8/17/1987|        4:20 PM| 65476| 10.012|             true|             Product|8/17/1987  &  4:2...|\n",
      "|      null|Female| 7/20/2015|       10:43 AM| 45906| 11.598|             null|             Finance|7/20/2015  &  10:...|\n",
      "|    Angela|Female|11/22/2005|        6:29 AM| 95570| 18.523|             true|         Engineering|11/22/2005  &  6:...|\n",
      "|   Frances|Female|  8/8/2002|        6:51 AM|139852|  7.524|             true|Business Development|8/8/2002  &  6:51 AM|\n",
      "|    Louise|Female| 8/12/1980|        9:01 AM| 63241| 15.132|             true|                null|8/12/1980  &  9:0...|\n",
      "|     Julie|Female|10/26/1997|        3:19 PM|102508| 12.637|             true|               Legal|10/26/1997  &  3:...|\n",
      "|   Brandon|  Male| 12/1/1980|        1:08 AM|112807| 17.492|             true|     Human Resources|12/1/1980  &  1:0...|\n",
      "|      Gary|  Male| 1/27/2008|       11:40 PM|109831|  5.831|            false|               Sales|1/27/2008  &  11:...|\n",
      "|  Kimberly|Female| 1/14/1999|        7:13 AM| 41426| 14.543|             true|             Finance|1/14/1999  &  7:1...|\n",
      "|   Lillian|Female|  6/5/2016|        6:09 AM| 59414|  1.256|            false|             Product|6/5/2016  &  6:09 AM|\n",
      "|    Jeremy|  Male| 9/21/2010|        5:56 AM| 90370|  7.369|            false|     Human Resources|9/21/2010  &  5:5...|\n",
      "|     Shawn|  Male| 12/7/1986|        7:45 PM|111737|  6.414|            false|             Product|12/7/1986  &  7:4...|\n",
      "|     Diana|Female|10/23/1981|       10:27 AM|132940| 19.082|            false|     Client Services|10/23/1981  &  10...|\n",
      "|     Donna|Female| 7/22/2010|        3:48 AM| 81014|  1.894|            false|             Product|7/22/2010  &  3:4...|\n",
      "+----------+------+----------+---------------+------+-------+-----------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df1=df.select(\"*\",concat(\"Start Date\",lit(\"  &  \"),\"Last Login Time\").alias(\"Date & Time\"))\n",
    "df1.show() #has Start date and last login time and Date&Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47225e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-------+-----------------+--------------------+--------------------+\n",
      "|First Name|Gender|Salary|Bonus %|Senior Management|                Team|         Date & Time|\n",
      "+----------+------+------+-------+-----------------+--------------------+--------------------+\n",
      "|   Douglas|  Male| 97308|  6.945|             true|           Marketing|8/6/1993  &  12:4...|\n",
      "|    Thomas|  Male| 61933|   4.17|             true|                null|3/31/1996  &  6:5...|\n",
      "|     Maria|Female|130590| 11.858|            false|             Finance|4/23/1993  &  11:...|\n",
      "|     Jerry|  Male|138705|   9.34|             true|             Finance|3/4/2005  &  1:00 PM|\n",
      "|     Larry|  Male|101004|  1.389|             true|     Client Services|1/24/1998  &  4:4...|\n",
      "|    Dennis|  Male|115163| 10.125|            false|               Legal|4/18/1987  &  1:3...|\n",
      "|      Ruby|Female| 65476| 10.012|             true|             Product|8/17/1987  &  4:2...|\n",
      "|      null|Female| 45906| 11.598|             null|             Finance|7/20/2015  &  10:...|\n",
      "|    Angela|Female| 95570| 18.523|             true|         Engineering|11/22/2005  &  6:...|\n",
      "|   Frances|Female|139852|  7.524|             true|Business Development|8/8/2002  &  6:51 AM|\n",
      "|    Louise|Female| 63241| 15.132|             true|                null|8/12/1980  &  9:0...|\n",
      "|     Julie|Female|102508| 12.637|             true|               Legal|10/26/1997  &  3:...|\n",
      "|   Brandon|  Male|112807| 17.492|             true|     Human Resources|12/1/1980  &  1:0...|\n",
      "|      Gary|  Male|109831|  5.831|            false|               Sales|1/27/2008  &  11:...|\n",
      "|  Kimberly|Female| 41426| 14.543|             true|             Finance|1/14/1999  &  7:1...|\n",
      "|   Lillian|Female| 59414|  1.256|            false|             Product|6/5/2016  &  6:09 AM|\n",
      "|    Jeremy|  Male| 90370|  7.369|            false|     Human Resources|9/21/2010  &  5:5...|\n",
      "|     Shawn|  Male|111737|  6.414|            false|             Product|12/7/1986  &  7:4...|\n",
      "|     Diana|Female|132940| 19.082|            false|     Client Services|10/23/1981  &  10...|\n",
      "|     Donna|Female| 81014|  1.894|            false|             Product|7/22/2010  &  3:4...|\n",
      "+----------+------+------+-------+-----------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final=df1.drop(\"Start Date\",\"Last Login Time\")\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e224124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.write.csv(\"Emp_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
