{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2828dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pySpark Datatype is used when schema cannot be defined using list or string\n",
    "#Data types types: struct,map,array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443fa4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd289a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02628636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7661f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/22 04:23:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"RDDExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44ca464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "786156cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[(1,'a',30),(2,'b',32)]\n",
    "user_schema=StructType([StructField(\"id\",IntegerType()),\n",
    "                        StructField(\"name\",StringType()),\n",
    "                        StructField(\"age\",IntegerType())\n",
    "                       ])\n",
    "df=spark.createDataFrame(data,user_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5848c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|name|age|\n",
      "+---+----+---+\n",
      "|  1|   a| 30|\n",
      "|  2|   b| 32|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4ba2bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+\n",
      "| id|   name|             hobbies|\n",
      "+---+-------+--------------------+\n",
      "|  1|  Alice|   [Reading, Hiking]|\n",
      "|  2|    Bob|[Swimming, Garden...|\n",
      "|  3|Charlie|           [Cooking]|\n",
      "|  4|  David|[Photography, Ski...|\n",
      "+---+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2= [\n",
    "    (1, \"Alice\", [\"Reading\", \"Hiking\"]),\n",
    "    (2, \"Bob\", [\"Swimming\", \"Gardening\", \"Painting\"]),\n",
    "    (3, \"Charlie\", [\"Cooking\"]),\n",
    "    (4, \"David\", [\"Photography\", \"Skiing\", \"Cooking\"])\n",
    "]\n",
    "user_schema2=StructType([StructField(\"id\",IntegerType()),\n",
    "                        StructField(\"name\",StringType()),\n",
    "                        StructField(\"hobbies\",ArrayType(StringType()))\n",
    "                       ])\n",
    "df2=spark.createDataFrame(data2,user_schema2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9ddc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get output as 1,Alice,Reading;1,Alice,hiking; 2,bob,swimming etc\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e32023a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+\n",
      "| id|   name|        col|\n",
      "+---+-------+-----------+\n",
      "|  1|  Alice|    Reading|\n",
      "|  1|  Alice|     Hiking|\n",
      "|  2|    Bob|   Swimming|\n",
      "|  2|    Bob|  Gardening|\n",
      "|  2|    Bob|   Painting|\n",
      "|  3|Charlie|    Cooking|\n",
      "|  4|  David|Photography|\n",
      "|  4|  David|     Skiing|\n",
      "|  4|  David|    Cooking|\n",
      "+---+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"id\",\"name\",explode(\"hobbies\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60a4f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id|   name|             hobbies|   newhobby|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  1|  Alice|   [Reading, Hiking]|    Reading|\n",
      "|  1|  Alice|   [Reading, Hiking]|     Hiking|\n",
      "|  2|    Bob|[Swimming, Garden...|   Swimming|\n",
      "|  2|    Bob|[Swimming, Garden...|  Gardening|\n",
      "|  2|    Bob|[Swimming, Garden...|   Painting|\n",
      "|  3|Charlie|           [Cooking]|    Cooking|\n",
      "|  4|  David|[Photography, Ski...|Photography|\n",
      "|  4|  David|[Photography, Ski...|     Skiing|\n",
      "|  4|  David|[Photography, Ski...|    Cooking|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"newhobby\",explode(\"hobbies\")).show()#creates new derived column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05872440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+\n",
      "| id|   name|    hobbies|\n",
      "+---+-------+-----------+\n",
      "|  1|  Alice|    Reading|\n",
      "|  1|  Alice|     Hiking|\n",
      "|  2|    Bob|   Swimming|\n",
      "|  2|    Bob|  Gardening|\n",
      "|  2|    Bob|   Painting|\n",
      "|  3|Charlie|    Cooking|\n",
      "|  4|  David|Photography|\n",
      "|  4|  David|     Skiing|\n",
      "|  4|  David|    Cooking|\n",
      "+---+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"hobbies\",explode(\"hobbies\")).show()#replaces existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5715b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------------------+-----------------------+\n",
      "|id |name   |hobbies                        |ingestion_date         |\n",
      "+---+-------+-------------------------------+-----------------------+\n",
      "|1  |Alice  |[Reading, Hiking]              |2023-09-22 04:49:24.115|\n",
      "|2  |Bob    |[Swimming, Gardening, Painting]|2023-09-22 04:49:24.115|\n",
      "|3  |Charlie|[Cooking]                      |2023-09-22 04:49:24.115|\n",
      "|4  |David  |[Photography, Skiing, Cooking] |2023-09-22 04:49:24.115|\n",
      "+---+-------+-------------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3=df2.withColumn(\"ingestion_date\",current_timestamp()).show(truncate=False)#try truncate=True ans see what happens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
